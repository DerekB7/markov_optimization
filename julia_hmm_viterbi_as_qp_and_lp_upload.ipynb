{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal: walk through Hidden Markov Model (forward pass) algebra and its link in to the Viterbi optimal path, to derive a quadratic programming formulation of the Viterbi solution.  From here the quadratic program will be converted to a linear program**\n",
    "\n",
    "Solving for most likely Viterbi optimal path (and associated 'score') via Quadratic Programming and/or Linear Programming is a useful and quite general way to check implementations of Viterbi -- by just following where the algebra takes you.  \n",
    "\n",
    "note: certain conventions used in the algebra are done for illustrative purposes --i.e. to make the underlying points as clear as possible.  Hence there are a small few adjustments needed to map from the algebra to the Julia code.\n",
    "\n",
    "The associated code was done in Julia 0.4.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of moving parts in this post. **For simplicity, this post virtually ignores differences between real valued outputs and integer constraints.** That is, I sometimes act as if we are solving for indicator variables $\\in \\{0,1\\}$ and other times for indicator variables $\\in [0,1]$.  **The reason is that this is expedient.**  The fact is we can toggle either interpretation we want as we work through the math.  The only assumption I make is that there is one unique Viterbi optimal path.  **At the *very* end of this post I address the issue of uniquenes and real values vs. Boolean Valued solutions, under the bold heading of \"A Final Note\".**\n",
    "\n",
    "as in past posts, let:\n",
    "\n",
    "$h = \\begin{bmatrix}\n",
    "1\\\\ \n",
    "1\\\\ \n",
    "\\vdots\\\\ \n",
    "1\n",
    "\\end{bmatrix}\n",
    "$\n",
    " \n",
    "What we have is an equation like  \n",
    "$Posterior_f \\propto D_{y_{n-1}} A  ...  D_{y_1}  A D_{y_0}Ax$\n",
    "\n",
    "This post assumes that there is a valid posterior with some probability > 0 in it.  \n",
    "\n",
    "I re-label things a bit -- as we are transitioning away from forward-backward to Viterbi and have different goals in mind:  \n",
    "$EndingProbability \\propto (D_{y_{n-1}}  A)  ...  (D_{y_1}  A)  (D_{y_0}A) starting$\n",
    "\n",
    "For notational simplicity let $B_{i} = (D_i A)$  \n",
    "$EndingProbability \\propto (B_{y_{n-1}})  ...  (B_{y_1})  (B_{y_0}) starting$\n",
    "\n",
    "Let's simplify this a bit and consider only 4 or so transitions  \n",
    "$EndingProbability \\propto B_{y_{3}} B_{y_{2}}  B_{y_1}  B_{y_0} starting$\n",
    "\n",
    "So For Viterbi, what we want is is the best path that leads through all of this:  \n",
    "$MAP_{ending}Probability \\propto grab(B_{y_{3}}) * grab(B_{y_{2}}) * grab( B_{y_1}) * grab(B_{y_0}) * grab(starting)$\n",
    "\n",
    "Where I've introduced --for thought experiment purposes-- a function 'grab' that grabs the best (scalar) choice from each $B_i$ *and* makes sure that there is a coherent chain from starting to ending.  \n",
    "\n",
    "Now once we have our head around the above thought experiement, we can switch to a negative log space equivalent  \n",
    "$-Log(MAP_{ending}Probability)  \\propto grab( -Log(B_{y_{3}}))+ grab( -Log(B_{y_{2}})) + grab( -Log( B_{y_1})) + grab(-Log(B_{y_0})) + grab(-Log(starting))$\n",
    "\n",
    "As a reminder, in this negative logspace equivalent world, we have gone from multiplying 'best' probabilities on a chain, to adding their negative logs.  Since the best chain must have probability > 0, no single best probability can be = 0.  Thus we know that all $BestProbabilities > 0$ and all $BestProbabilities \\leq 1$ -- in logspace this means all value are $ \\leq 0$, and thus in the negative logspace world, we have all values $ \\geq 0$ -- i.e. the negative logspace adjustment allows us to make everything additive, and strictly non-negative, which is quite nice.\n",
    "\n",
    "\n",
    "*The above notation is cumbersome: here are a few more transformations so we can abstract and focus on the important stuff*\n",
    "\n",
    "1. I am going to drop the $\\propto$ sign here for minor semantic reasons.  If it makes you uncomfortable, you can write it back in.  The idea, though, is for a given legal setup, in our problem, there will be one best / MAP / viterbi optimal path score, and that is what we are calculating here.  Note: there are some subtleties around the case where multiple paths have the same MAP score (i.e. non-unique optimal path).  I put some comments in the code to discuss some of this.  This post assumes that there is a single optimal path associated with MAP score.  \n",
    "\n",
    "2. Let $-Log(B_{y_{i}}) = C_i$  That is $C_i$ means that ith appropriate negative log transformed matrix.  Once you are comfortable with this point (and once it's been coded), you can just think of it as some matrix $C_i$.  You don't need to worry where it came from.\n",
    "\n",
    "3. I will relabel the -Log(starting) to NominalStartVec.  This helps unclutter our thinking.  (And once the transformation has been coded, you don't need to worry about where it came from.)\n",
    "\n",
    "4. Also: forget about the $x$ and $y$ earlier in this post! I will be using them again with unrelated meaning!  It's easy to run out of coherent letters in an alphabet when using linear algebra.  So please wipe the prior usage of $x$ and $y$ from your memory!\n",
    "\n",
    "So what we have here is:\n",
    "\n",
    "$_{LogWorld}MAP_{ending}Probability = grab( C_{3})+ grab( C_{2}) + grab(C_{1}) + grab(C_{0}) + grab(NominalStartVec))$\n",
    "\n",
    "Now we have two things to do.  \n",
    "\n",
    "First replace this all powerful grab function with something mathematically tractable. That yields a quadratic program.  \n",
    "\n",
    "The optional second step will be to decompose the quadratic program in a particular way so that it becomes linear in its objective function -- much subtler and perhaps harder to follow.\n",
    "\n",
    "\n",
    "**Step one: convert grab into something mathematically tractable**\n",
    "\n",
    "To hopefully make this simple, let's say there are 3 possible states at any given time.  (One oddity: by convention, I start counting at zero, as many programming languages do.  The accompanying code is in Julia.  In addition to slightly different variable designations that I use, I'd highlight that Julia *starts counting at one*.  So there will be some gaps between the Julia setup and the algebraic representation.  These gaps should are minor.)\n",
    "\n",
    "$v = \\begin{bmatrix}\n",
    "v_{0}\\\\ \n",
    "v_{1}\\\\ \n",
    "v_{2}\n",
    "\\end{bmatrix}\n",
    "$ $w = \\begin{bmatrix}\n",
    "w_{0}\\\\ \n",
    "w_{1}\\\\ \n",
    "w_{2}\n",
    "\\end{bmatrix}\n",
    "$ $x = \\begin{bmatrix}\n",
    "x_{0}\\\\ \n",
    "x_{1}\\\\ \n",
    "x_{2}\n",
    "\\end{bmatrix}\n",
    "$ $y = \\begin{bmatrix}\n",
    "y_{0}\\\\ \n",
    "y_{1}\\\\ \n",
    "y_{2}\n",
    "\\end{bmatrix}\n",
    "$ $z = \\begin{bmatrix}\n",
    "z_{0}\\\\ \n",
    "z_{1}\\\\ \n",
    "z_{2}\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "For the avoidance of doubt: **each scalar item in a given vector is an indicator variable**.  That is: it takes on a value of 0 or 1.  There is also a very natural constraint that **the sum of any given vector should equal 1**.  That is you can have one indicator variable 'chosen' and then rest are all zero'd out. The fact that the sum of scalar values in any given vector equals one means that, in effect, we *could* think of each vector being like a probability distribution.  This is not needed for the quadratic programming formulation, but becomes quite useful when thinking about how to convert the QP into an LP.\n",
    "\n",
    "So I've introduced the above vectors, and we end up with the below equation, in quadratic form.  \n",
    "\n",
    "$_{LogWorld}MAP_{ending}Probability = z^T C_{3} y + y^T C_{2} x  + x^T C_{1} w + w^T C_{0}v + v^T NominalStartVec$\n",
    "\n",
    "\n",
    "\n",
    "If you understand the above, you can see its very clear links to a (hidden) markov chain model.  We are selecting only one coherent path on the chain, and because we did a negative log space transformation, we can add up all of these 'weights' on the chain.  This is the simplest form of a quadratic program: we have an objective function (i.e. minimize $_{LogWorld}MAP_{ending}Probability $ but all of the constraints are linear in nature).\n",
    "\n",
    "- - - \n",
    "*interlude*\n",
    "If you'd like, you can 'open up' the $C_i$'s and convert them (and NominalStartVec) back from negative log space to 'regular probability' space.  It's important that we don't change $v, w, x, y, z$ -- they are merely indicator variables being used instead of the 'grab' function.  Being in logspace or not has no impact on them.\n",
    "\n",
    "$EndingProbability \\propto (z^T(D_{y_{3}}A)y) * (y^T(D_{2}A)x) * (x^T(D_{y_1}A)w) * (w^T(D_{y_0}A)v) * (v^T starting)$\n",
    "\n",
    "The above is a sequence of scalar multiplications: i.e. we have:\n",
    "\n",
    "$(someScalar)*(AnotherScalar)*(yetAnotherscalar)*(oneMoreScalar)*(aFinalScalar)$.  \n",
    "\n",
    "So what you see above is quite literally the product of a bunch of different probabilities.  I.e. we've described an arbitrary single pass through a hidden markov model.  In Viterbi we do this while trying to maximize the value of said product, *or* we go to negative log space and minimize the value of this sum. From a Linear or Quadratic Programming standpoint, an equation like \n",
    "\n",
    "$EndingProbability \\propto (z^T(D_{y_{3}}A)y) * (y^T(D_{2}A)x) * (x^T(D_{y_1}A)w) * (w^T(D_{y_0}A)v) * (v^T starting)$\n",
    "\n",
    "is not at all useful.  The negative logspace equivalent, however, is very useful.  It still can be nice to think about the above equation though.  It is nice in how readable it is, it can directly be drawn in terms of a trellis diagram, etc. and at its core, the above equation is the generator of this entire post.  \n",
    "\n",
    "*end interlude*\n",
    "- - - \n",
    "\n",
    "\n",
    "Note: that the domain for any scalar value in vectors $v, w, x, y, z$ is [0, 1].  Also note that $C_i$ has strictly nonnegative values.  So *in effect* we have a quadratic optimization problem that is convex.  (I say *in effect* here, in the same way that I'd say for  single variable function $f(a) = a^3$ is convex if we insist that $a$ is non-negative.) \n",
    "\n",
    "Solvers for constrained convex quadratic problems are quite effective.  That said they are still fairly heavy duty machinery, and I noticed some very odd behavior Julia with respect to the solver I used.  E.g. when I put in redundant dummy constraints like that the sum of all elements in those 5 vectors $v, w, x, y, z$ in aggregate is less than 6 -- this somehow changes the answer to something suboptimal.  Clearly each has a max value of 1, and there are 5 of them -- so max value is 5 and the constraint should not impact things.  When I played around with things like this, I would notice changes in the solution from time to time -- and they should not have changed at all.  It is certainly possible that I could have eliminated this odd behavior by using another solver, or tweaking the formulation somewhat.\n",
    "\n",
    "But the point remains: a Quadratic Program is a heavier duty piece of machinery, and is harder to interpret than a Linear Program.\n",
    "\n",
    "\n",
    "**The above will yield a working quadratic program. Associated code for such a program is shown in the below.**\n",
    "\n",
    "Again, the essence of the objective function for this QP formulation is:\n",
    "$_{LogWorld}MAP_{ending}Probability = z^T C_{3} y + y^T C_{2} x  + x^T C_{1} w + w^T C_{0}v + v^T NominalStartVec$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "quadratic_program_objective_function (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function quadratic_program_objective_function(likelihood_matrix, A, y_vec, x_box, nominal_prior_x)\n",
    "    \"\"\"\n",
    "    The objective function for the QP formulation.  \n",
    "    \n",
    "    NOTE THIS IS SETUP FOR THE VITERBI COIN EXAMPLE, \n",
    "    hence there is some special handling around time 1\n",
    "    \n",
    "    This approach in essence, should work, though it is something of a hack as \n",
    "    it perturbs A (and the likelihood function) ever so slightly, and blows up associated sparsity\n",
    "    \n",
    "    Getting the quadratic program to properly take advantage of sparsity is challenging.  \n",
    "    As noted at the very end of this writeup, taking advantage of sparsity \n",
    "    in the LP formulation is much easier, though that is as of yet and unimplemented optimization.  \n",
    "    \n",
    "    The small perturbation of all cells by epsilon is the easiest way\n",
    "    to (approximately) solve the problem being posed and keep the essence of the problem most clear\n",
    "    \"\"\"\n",
    "    epsilon = 0.000000000000000001\n",
    "    # interesting side note: we could vary the epsilon by a TINY amount, at random \n",
    "    \n",
    "    assert(length(size(y_vec)) == 1) # a proper vector here\n",
    "    entries_in_y = size(y_vec)[1] # then we grab its dimension here\n",
    "        \n",
    "    collector = dot(nominal_prior_x , x_box[:,1])\n",
    "    # recall nominal_prior_x is already in - log space\n",
    "\n",
    "    for idx = 1:entries_in_y        \n",
    "        # the_diagonal_piece = diagm(likelihood_matrix[:,y_vec[idx]]) \n",
    "        # not needed if we use broadcasting\n",
    "        if idx > 1\n",
    "            adj_A = ( likelihood_matrix[:,y_vec[idx]] .* A) + epsilon\n",
    "            # below is the correct linear algebra setup, but above is the broadcasting equivalent\n",
    "            # adj_A = *(the_diagonal_piece, A) + epsilon            \n",
    "        else\n",
    "            # special handling needed for the first toss in the Viterbi coin example from  6.008.1x\n",
    "            the_diagonal_piece = diagm(likelihood_matrix[:,y_vec[idx]])\n",
    "            adj_A = the_diagonal_piece + epsilon\n",
    "        end        \n",
    "        adj_A = -log(adj_A)\n",
    "                \n",
    "        new_vec = *(adj_A, x_box[:, idx])\n",
    "        \n",
    "        collector += dot(x_box[:, idx + 1], new_vec)        \n",
    "\n",
    "    end\n",
    "    return collector\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "******************************************************************************\n",
      "This program contains Ipopt, a library for large-scale nonlinear optimization.\n",
      " Ipopt is released as open source code under the Eclipse Public License (EPL).\n",
      "         For more information visit http://projects.coin-or.org/Ipopt\n",
      "******************************************************************************\n",
      "\n",
      "note: ignore floating point nits -- e.g. 0.9999999976 should be thought of as 1.0\n",
      "--------------------------------------------------\n",
      "Variable x:Values: [1.0,0.0,1.0,0.0,2.3771984814787784e-9,0.9999999976228016,0.0,1.0,0.0,1.0]\n",
      "Objective value: 3.923316180950796\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# this is the quadratic setup.  \n",
    "# encapsulating this in a function would likely lead to better performance, \n",
    "# though the 'open' setup here allows the user to more easily explore results\n",
    "\n",
    "using JuMP\n",
    "using Ipopt\n",
    "mymodel = Model(solver=IpoptSolver(print_level=0))\n",
    "\n",
    "# For the avoidance of doubt:\n",
    "# A is the transition matrix, and L is a collection of likelihood vectors\n",
    "\n",
    "A = [3/4  1/4; \n",
    "     1/4  3/4]\n",
    "\n",
    "L = [1/4 1/2  1/2; \n",
    "     1/8 1/4  3/4]\n",
    "\n",
    "assert(size(A)[1]== size(A)[2]) # that A is square\n",
    "r_states = size(A)[1]\n",
    "\n",
    "y_vec = [2, 3, 3, 3]\n",
    "nominal_prior_x = [1/4, 1/8]\n",
    "\n",
    "nominal_prior_x = nominal_prior_x / sum(nominal_prior_x)\n",
    "nominal_prior_x = -log(nominal_prior_x)\n",
    "# convert to logspace before beginning \n",
    "\n",
    "n_updates = size(y_vec)[1]\n",
    "\n",
    "@variable(mymodel, 0<=x[i = 1:r_states*(n_updates +1)]<=1)\n",
    "x_box = reshape(x, (r_states, (n_updates + 1)  ))\n",
    "# reshape x into a matrix called x_box.  This makes handling easier\n",
    "\n",
    "ones_v_days_as_row_vec = ones(1,r_states)\n",
    "\n",
    "# linear equality constraint\n",
    "my_constraint = @constraint(mymodel, *(ones_v_days_as_row_vec, x_box) .== 1) \n",
    "\n",
    "# quadratic objective function\n",
    "z = quadratic_program_objective_function(L, A, y_vec, x_box, nominal_prior_x) \n",
    "\n",
    "\n",
    "myobjective = @objective(mymodel, Min, z ) # basic quadratic form\n",
    "\n",
    "# Solve mymodel\n",
    "solve(mymodel)\n",
    "\n",
    "print(\"note: ignore floating point nits -- e.g. 0.9999999976 should be thought of as 1.0\")\n",
    "print(\"\\n--------------------------------------------------\\n\")\n",
    "\n",
    "println(\"Variable x:Values: \", getvalue(x))\n",
    "\n",
    "println(\"Objective value: \", getobjectivevalue(mymodel), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x[1]1.0\n",
      "x[3]1.0\n",
      "x[6]0.9999999976228016\n",
      "x[8]1.0\n",
      "x[10]1.0\n"
     ]
    }
   ],
   "source": [
    "for item in x\n",
    "    if getvalue(item) >0.9\n",
    "        print(item, getvalue(item), \"\\n\")\n",
    "    end\n",
    "end\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The next optional step is: convert this to a linear program using some clever transformations.  Warning: This may be hard to follow.**\n",
    "\n",
    "*To my mind: the LP formulation is much better from a computational standpoint.  However, the essence of the problem is best understood in the algebra associated with the quadratic formulation.*\n",
    "\n",
    "The idea here is to unpack these quadratic terms into linear combinations and then come up with a very clever constraint at the end to ensure you still get the same result.  (In effect the flourish at the end is to find a hidden probability distribution, so that when you sum along a given axis of some square, you find a 'hidden' probability distribution, and when you sum over the entire valid pmf, you know its sum must be equal to one.  This is reminiscent of my approach to deriving mean and variance for the Poisson distribution.)\n",
    "\n",
    "So again, for quadratic programming purposes, we have:\n",
    "\n",
    "$ = z^T C_{3} y + y^T C_{2} x  + x^T C_{1} w + w^T C_{0}v + v^T NominalStartVec$\n",
    "\n",
    "We can take the above and decompose it as follows:\n",
    "\n",
    "$=  h^T \\big(C_{3} \\circ (zy^T) \\big) h + h^T \\big( C_{2} \\circ  (yx^T) \\big)h  + h^T \\big( C_{1} \\circ (xw^T) \\big)h + h^T \\big(  C_{0} \\circ (wv^T) \\big)h +  h^T \\big(NominalStartVec \\circ v \\big) $\n",
    "\n",
    "Notice that $\\circ$ denotes the Hadamard product. The above decomposition is quite useful, though perhaps not something seen all that often. \n",
    "\n",
    "In this world, our new linear constraint would be to make sure that each of the square matrices that $C_i$ is being (hadamard) multiplied by, sums to one.  The above equation should be interpretted as our implicit *objective function*.  This post will shortly 'peek inside' the hadamard products, and consider summing across the columns or rows of something like $yx^T$.  To be certain, we are not using some sort of legal Linear Algebra manipulation of the above equation.  The 'peek inside' operations are oriented towards our *constraints*, not our *objective function*.  \n",
    "\n",
    "*To be clear*: The way we leave the quadratic domain for our objective function is by no longer explicitly using $u, v, x, y, z$, but instead using $h^T \\big( C_{i} \\circ  SomeSquare \\big)h$ and modelling out all of those SomeSquare's.  (In the code I stack all of these SomeSquare matrices on top of each other in something I call an x_tensor so you really have $SomeSquare_k$ for k = 0, 1, 2, ... last_observation.  But I don't want to confuse people too much with different terminologies and notation here, so don't dwell on how the collection is organized.)  \n",
    "\n",
    "The idea though is we no longer explicitly model out these vectors $u, v, x, y, z$ and instead we model out SomeSquare's.  However, we still need to *think* about the implict  $u, v, x, y, z$ because from a mathematical standpoint they still implicitly exist in the various SomeSquare terms.  (Note I omit discussion of how to deal with the one oddball term on the right -- $h^T \\big(NominalStartVec \\circ v \\big)$ -- because once you understand how to deal with the the SomeSquare's, it becomes obvious on how to deal with that piece.  The analogy is just figuring out how to kickstart a recurrence.)  \n",
    "\n",
    "\n",
    "*onward to the constraints*\n",
    "\n",
    "So for some term: \n",
    "\n",
    "$h^T \\big( C_{i} \\circ  SomeSquare \\big)h$\n",
    "\n",
    "there is a constraint\n",
    "$sum(SomeSquare) = 1$\n",
    "\n",
    "or equivalently\n",
    "\n",
    "$h^T \\big(SomeSquare \\big) h = 1$\n",
    "\n",
    "A subtle but important point is that this is equivalent to part of what we had for our quadratic program.  That is if you look at, for example: \n",
    "\n",
    "$h^T \\big( C_{2} \\circ  (yx^T) \\big)h$\n",
    "\n",
    "where, again $yx^T$ only exists implicitly-- if we insist that \n",
    "\n",
    "$h^T (yx^T)h = 1$\n",
    "\n",
    "This is equivalent to \n",
    "\n",
    "$h^T y  = 1$ *and* $x^Th = 1$  We'll return to this point shortly.  \n",
    "\n",
    "The thing we are mising in our current linear program is: we need to enforce the daisy chaining of the quadratic program that made sure vectors were consistent across terms in the series.  For example, we need to make sure that \n",
    "\n",
    "when we look at $z^T C_{3} y$,\n",
    "\n",
    "and we enforce that \n",
    "\n",
    "$h^T (zy^T)h = 1$\n",
    "\n",
    "which implies \n",
    "\n",
    "$h^T z  = 1$ *and* $y^Th = 1$\n",
    "\n",
    "**AND we need to be sure that we are using the exact same implicit y vector for the SomeSquare associated with** $zy^T$ **as we did with the SomeSquare associated with **$yx^T$.  That is the subject of the following discussion.  \n",
    "\n",
    "- - - - \n",
    "Now for the most challenging / subtle part of this writeup: re to enforce the implicit daisy chain:  \n",
    "\n",
    "The idea is to play around with various 'outer products' between vectors, recognize them implicitly in our series, and see how we can recover the implicity underlying vectors across terms.  \n",
    "\n",
    "Key idea: Let's look at this term in the series.  \n",
    "\n",
    "$h^T \\big( C_{2} \\circ  (yx^T) \\big)h  = sum\\big( C_{2} \\circ  (yx^T) \\big) = sum\\big( C_{2} \\circ  (ParticularSomeSquare) \\big)$ \n",
    "\n",
    "\n",
    "What is going on inside the sum?   $C_{2}$ is given to us, and not that interesting.  What we need is to look at the implicit vectors underlying $ParticularSomeSquare$.  \n",
    "\n",
    "So we examine the implicit outer product here:\n",
    "\n",
    "$\n",
    "yx^{T} = \\begin{bmatrix}\n",
    "y_{0}x_{0} &y_{0}x_{1}  &y_{0}x_{2} \\\\ \n",
    "y_{1}x_{0} &y_{1}x_{1}  &y_{1}x_{2}\\\\ \n",
    "y_{2}x_{0} &y_{2}x_{1}  &y_{2}x_{2}\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "Now that we've looked under the hood, recall the goal is to find an underlying constraint here. If we wanted to sum up the elements by items per column, we *could* think of it as\n",
    "\n",
    "$\n",
    "h^T (yx^{T}) = \\begin{bmatrix}\n",
    "noise*x_{0} & noise*x_{1}  &noise*x_{2} \\\\ \n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "The reader may be able to guess, the noise, but there is an even easier approach: use associativity.\n",
    "\n",
    "$\n",
    "(h^T y) x^{T} = 1*\\begin{bmatrix}\n",
    "x_{0} & x_{1}  &x_{2} \\\\ \n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "\n",
    "That is we've 'pinned down' the $x_0$, $x_1$, $x_2$ terms, multiplied by a scalar of 1.  Why is the scalar 1? A few paragraphs ago we noted: $h^T y = 1$\n",
    "\n",
    "\n",
    "Now, if instead we wanted to sum up the elements by items per row, we *could* think of it as \n",
    "\n",
    "$(yx^{T})h $\n",
    "\n",
    "or, using associativity: \n",
    " $(yx^{T})h = y(x^T h) = \\begin{bmatrix}\n",
    "y_{0}\\\\ \n",
    "y_{1}\\\\ \n",
    "y_{2}\n",
    "\\end{bmatrix} * 1\n",
    "$\n",
    "\n",
    "again, a few paragraphs up we noted $x^T h = 1$\n",
    "\n",
    "\n",
    "**The big idea** \n",
    "\n",
    "Left or right multiplying our SomeSquare by the ones vector allows us to isolate the underlying implicit vector of our choosing.  The below flushes this out in some more detail.  \n",
    "- - - -\n",
    "*begin extra detail* \n",
    "\n",
    "$yx^T$ exists as ParticularSomeSquare and the underlying vectors only implicitly exist.  $yx^T$ has a bunch of zeros in it, and *single* cell equal to 1. This is our goal from a probabilistic modelling standpoint, and we've already enforced this condition.  (If you get lost, think about the fact that the sum of this square must equal 1, and I am allowing the reader to consider this as a binary Integer Program -- this latter piece is technically not needed but it makes the thought experiment a lot easier to follow).  \n",
    "\n",
    "**claim** if $yx^T$ has single cell = 1, and the rest all zeros, this must be because there is some implicit $y_i^* = 1$  and all other scalar values $y$ are zero -- i.e. $y_j =0$ where $i^* \\neq j$ .  AND there must be *one* implicit $x_i = 1$ with all other values in $x$ = 0. \n",
    "\n",
    "The proof is easy:  Where all scalars are Boolean in $x$ and $y$. \n",
    "\n",
    "we have the constraint: \n",
    "$h^T(xy^T)h = 1$\n",
    "\n",
    "by associativity: \n",
    "$(h^Tx) * (y^Th) = 1$\n",
    "\n",
    "and given that we are dealing with bools, we know that the above holds if and only if $(1)* (1) = 1$\n",
    "\n",
    "Thus $h^Tx = 1$ and $y^T h = 1$\n",
    "\n",
    "which, again, given that we are dealing with bools, implies one and only one $y_i = 1$ and one and only one $x_i = 1$\n",
    "\n",
    "*end extra detail* \n",
    "- - - -\n",
    "\n",
    "Now, with that out of the way, we look at a neighboring term: \n",
    "\n",
    "$h^T \\big(C_{3} \\circ (zy^T) \\big) h$\n",
    "\n",
    "if we 'zoom in'  on $zy^T$ and we summed up items by column, we'd get:\n",
    "\n",
    "$\n",
    "h^T (zy^{T}) = (h^T z)y^{T} = 1*y^{T} = \\begin{bmatrix}\n",
    "y_{0} & y_{1}  & y_{2} \\\\ \n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "\n",
    "\n",
    "And *this* is the key idea. To be clear, the above manipulations with the h vector are *not* Linear Algebra implications related to the *value* of $h^T \\big(C_{3} \\circ (zy^T) \\big) h$.  \n",
    "\n",
    "Instead, they are clever ways to tease out a *constraint*.  That is, when we do the above we create a squeeze that allows us to enforce consistency for our implicit $y$ vectors.  Specifically, we have: \n",
    "\n",
    "$vec(yx^{T}h) = vec(h^T zy^{T})$\n",
    "\n",
    "(Small note: In the spirit of Julia: I wrapped a vec() around these to expressions, that way the column vector from $yx^{T}h$ can be treated as a 1 dimensional vector, and the row vector from $h^T zy^{T}$ can also be treated as a 1 dimensional vector.  Note that Julia would ask that you use $.==$ to designate element-wise equality comparisons, but that is a minor implementation detail)  \n",
    "\n",
    "Put differently, by enforcing $vec(yx^{T}h) = vec(h^T zy^{T})$\n",
    "\n",
    "we make sure implicit $y_0$ on the left = implicit $y_0$ on the right, *and* that implicit $y_1$ on the left = implicit $y_1$ on the right *and* implicit $y_2$ on the left = implicit $y_2$ on the right\n",
    "\n",
    "And we can use concept for all adjacent terms in our series to re-write our constraints as linear in nature.  That is, repeatedly using the above constraint between adjacent terms in our series enforces the 'daisy chaining' that occurred in the quadratic objective function. (We just need a touch of special handling to 'kickstart' the process with the far right term $h^T \\big(NominalStartVec \\circ v \\big)$.)\n",
    "\n",
    "**Near final note:**\n",
    "\n",
    "In effect the LP form of this project has all linear constraints, and a linear objective function but has $O(m^2 k)$ constraints / variables to worry about, whereas the quadratic form has $O(m k)$ constraints / variables to worry about, but has a quadratic objective function.  \n",
    "\n",
    "This is a good trade in all cases known to your author, given how heavily optimized and interpretable Linear Program solvers are -- both in terms of purely mechanical issues plus the powerful heuristics that augment them.\n",
    "\n",
    "There is a particular kicker here: in your author's view, the LP formulation is *much* easier to properly 'sparsify' for HMM's like in our project.  (Technically this should be viewed as a further optimization that has not yet been implemented in the accompanying code, though.)  On top of that the LP program has a 'switch' that can be flipped to officially make the variables involved into (binary) integers if the reader so desires  -- *some* solvers like Gurobi will do mixed integer quadratic programming but this is even more exotic than linear mixed integer programming. \n",
    "\n",
    "**Final note: re: Mixed Integer Programs vs Linear Programs**\n",
    "\n",
    "This posting used the idea of our indicator variables being $\\in \\{0,1\\}$ and $\\in [0,1]$ interchangeably because it was expedient to do so.  \n",
    "\n",
    "In general, running a Mixed Integer Program will yield materially different results than a Linear Program (though there is a whole area of graph / matrix theory devoted to when they will not differ).  This post's approach to this possible divergence is quite simple: look to the underlying problem.  If the underlying problem has one unique Viterbi best solution, then in principle a correct binary Integer Program folmulation will solve for it.  If you relax said Integer Program to become a Linear Program $\\in [0,1]$, said program *must* solve for the same solution.  \n",
    "\n",
    "A much too short sketch of the proof uses the following exchange argument.  The idea is pick some $ 0 < \\epsilon \\leq 1$ (it can have standard and non-standard parts if you like, though non-standard parts are 'rounded off' in the end -- both in standard analysis and even further with floating point precision).  Assume the Integer Program and/or Viterbi code has an optimal solution $S$, that solves for implicit $Path_i = 1$ and all 'competitors' = 0.  The Linear Program's optimal solution $S^*$ solves for $Path_i = 1 - \\epsilon$ and some $Path^* = \\epsilon$.  Yet this raises a contradiction -- because there is assumed to be one single Viterbi optimal path, $S^*$ can be improved as $\\epsilon \\to 0$.  \n",
    "\n",
    "Put differently there is a contradiction because $S$ is better than $S^*$ -- and Linear Programs can solve for everything Integer Programs can (and more). So the above example suggests that a Linear Program had an optimal feasible solution and instead 'selected' something worse -- *that* is not something that happens.  \n",
    "\n",
    "- - - -\n",
    "Note: the LP derivation I came up with -- I've learned -- is almost identical to something called a Network Optimization or Network Flow problem.  Put differently, with a minor tweak, my LP formulation *is* a network optimization problem.  In addition to having extremely fast specialized LP solvers associated with them, Network Programs naturally have integer solutions associated with them.  This is probably the easiest way to think about the integer solution that the above approach derives.\n",
    "- - - -\n",
    "\n",
    "Now if the Viterbi optimal 'score' does not have a single unique path, the LP version may give you a 'mixed strategy'.  The idea here is that you will still have a useful optimal score to check against your Viterbi optimal score (assuming you use the same scaling factors in both problems) and they must match. Having a uniquely derived optimal score *was* the point of this whole approach, afterall.  Stepping back a bit: recall that the whole point of this very involved writeup was to come up with a useful way to check your Viterbi algorithm's results.  And if you find a mismatch in optimal scores -- you know that at least one of the algorithms has an incorrect result.  \n",
    "\n",
    "\n",
    "(If for some reason you *still* are unhappy with the LP returning a mixed strategy in the case of a non-unique optimal path, there are various things that you could do -- the laziest of course would be to just 'flip the switch' and make it a binary Integer Program.)  \n",
    "\n",
    "After all is said and done the LP approach to this problem is quite interesting.  However it only really exists to check results for Viterbi.  For an even faster way to check sparse Viterbi results, consider an optimized graph search algorithm -- especially Dijkstra for sparse graphs.  \n",
    "\n",
    "What is interesting about both the QP and LP formulations, however, is that one doesn't need to understand or the specifics of the Viterbi algorithm-- by just following the 'physical' structure of the hidden markov model and the associated linear algebra, you can uncover quite powerful mathematical programming tools to solve the problem for you.  This is a complementary way to view the underlying problem, and can yield more general insights that extend to aparently unrelated domains-- e.g. when analyzing / optimizing the number of potential connection of a neural network with $x$ hidden nodes and a flexibile amount of hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LP_objective_function (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "function LP_objective_function(likelihood_matrix, A, y_vec, x_tensor, nominal_prior_x, v)\n",
    "    \"\"\"\n",
    "    This is the Linear Objective function for the LP version of checking Viterbi\n",
    "    \n",
    "    To cut to the chase, this approach this approach employs something of a hack as it\n",
    "    perturbs A ever so slightly before taking a logarithm\n",
    "    \n",
    "    Setting this up as a 'proper' sparse optimization, without mangling the essense\n",
    "    of what is going on, is quite manageable but left as a subsequent optimization.  \n",
    "    \n",
    "    i.e. doing so would improve computational speed, \n",
    "    but add complications without adding improving insight\n",
    "    \n",
    "    \"\"\"\n",
    "    epsilon = 0.000000000000000001\n",
    "        \n",
    "    assert(length(size(y_vec)) == 1) # a proper vector here    \n",
    "    entries_in_y = size(y_vec)[1] # then we grab its dimension here\n",
    "    \n",
    "    m, n = size(x_tensor[:,:,1])\n",
    "    assert(m == n)  \n",
    "    # i.e. the tensor should be composed of square matrices stacked on top of each other\n",
    "    \n",
    "    collector = dot(nominal_prior_x, v) \n",
    "    # nominal_prior_x is ALREADY in - log space\n",
    "\n",
    "    for idx = 1:entries_in_y        \n",
    "        # the_diagonal_piece = diagm(likelihood_matrix[:,y_vec[idx]]) \n",
    "        # not needed if we use broadcasting\n",
    "        if idx > 1 \n",
    "            adj_A = (likelihood_matrix[:,y_vec[idx]] .* A) + epsilon\n",
    "            # below is the correct linear algebra setup, but above is the broadcasting equivalent\n",
    "            # adj_A = *(the_diagonal_piece, A) + epsilon            \n",
    "        else \n",
    "            # again special handling for the first instance is required in Viterbi coin example\n",
    "            # in coin tossing example we start with a coin toss \n",
    "            # i.e. there is no matrix A product 'just before dawn'\n",
    "            # so if idx == 1, there is just a likelihood function, no matrix A included\n",
    "            the_diagonal_piece = diagm(likelihood_matrix[:,y_vec[idx]])\n",
    "            adj_A = the_diagonal_piece + epsilon\n",
    "        end        \n",
    "        adj_A = -log(adj_A)\n",
    "        # recall this log transformation process is being -- inefficiently done, over and over \n",
    "        # clearly there are optimization opportunities available here, \n",
    "        # though they are outside the scope of what the purpose of this code / writeup is\n",
    "       \n",
    "#         collector += sum(adj_A .* x_tensor[:,:,idx]) # grab slice off the top and do hadamard\n",
    "        # the above line is correct but perhaps too pythonic.  Julia asks that we use the below:\n",
    "        append!(collector, sum(adj_A .* x_tensor[:,:,idx]))# grab slice off the top and do hadamard\n",
    "        # specifically, if you use the += for a LARGE program, you'll get the below warning:\n",
    "#         WARNING: The addition operator has been used on JuMP expressions a large number of times. \n",
    "#         This warning is safe to ignore but may indicate that model generation is slower than \n",
    "#         necessary. For performance reasons, you should not add expressions in a loop. \n",
    "#         Instead of x += y, use append!(x,y) to modify x in place. If y is a single variable, \n",
    "#         you may also use push!(x, coef, y) in place of x += coef*y.\n",
    "        \n",
    "    end\n",
    "    return collector\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "do_the_LP (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using JuMP\n",
    "\n",
    "using Cbc\n",
    "\n",
    "\n",
    "function do_the_LP(y_vec)\n",
    "\n",
    "    mymodel = Model(solver= CbcSolver())    \n",
    "    # For the avoidance of doubt:\n",
    "    # A is the transition matrix, and L is a collection of likelihood vectors\n",
    "\n",
    "    A = [3/4  1/4; \n",
    "         1/4  3/4]\n",
    "\n",
    "    m, n = size(A)\n",
    "\n",
    "    assert(m == n)\n",
    "\n",
    "\n",
    "    L = [1/4 1/2  1/2; \n",
    "         1/8 1/4  3/4]\n",
    "\n",
    "    # y_vec = [2, 3, 3, 3]    \n",
    "    nominal_prior_x = [1/4, 1/8]\n",
    "\n",
    "    nominal_prior_x = nominal_prior_x / sum(nominal_prior_x)\n",
    "    nominal_prior_x = -log(nominal_prior_x)\n",
    "    # convert to logspace before beginning \n",
    "\n",
    "    k_depth = size(y_vec)[1]\n",
    "\n",
    "    # see comments\n",
    "    # integer programming setup is shown below, if the user is so interested\n",
    "    # @variable(mymodel, x[i = 1: m*n*k_depth], Bin)\n",
    "    # @variable(mymodel, v[i = 1: m], Bin) \n",
    "\n",
    "    # comment out the below lines for x,v and uncomment the above two lines, \n",
    "    # to make this into a formal integer program\n",
    "\n",
    "    @variable(mymodel, 0<=x[i = 1: m*n*k_depth]<=1)\n",
    "    @variable(mymodel, 0<=v[i = 1: m]<=1) \n",
    "    \n",
    "    \n",
    "\n",
    "    # v kickstarts this process -- it relates to the prior, doesn't need its own 'square'\n",
    "    # as such I keep it separate from x \n",
    "    # because x is a sequence of square matrices stacked on top of each other (in tensor)\n",
    "\n",
    "    x_tensor = reshape(x, (m, n, k_depth))\n",
    "\n",
    "    ones_vc = ones(m,1) # this is a column ones vector\n",
    "\n",
    "\n",
    "    # All constraints are actually Linear Equalities\n",
    "    mini_kickstart_constraint = @constraint(mymodel, sum(v) == 1) \n",
    "    # similar to my_constraint, but just used to kickstart this process\n",
    "\n",
    "    my_constraint = @constraint(mymodel, [kdx = 1: k_depth], sum(x_tensor[:,:,kdx]) == 1)\n",
    "    # in some sense you don't actually need this constraint, and I removed it \n",
    "    # to make the model seem more 'network flow like'... but it turns out things go a lot faster with it in\n",
    "    # specifically I ran a case where my_y_vec = rand(1:3, 100000), and it randomly made a vector\n",
    "    # then I solved the problem with this constraint commented out and it took 834.095970 seconds\n",
    "    # then I solved the problem with this constraint in, and it took 40.075415 seconds\n",
    "    # the difference is kind of shocking\n",
    "    \n",
    "    # in effect: you must select one cell in each of the square matrices -- \n",
    "    # and all other values are zero\n",
    "\n",
    "    kickstart_constraint = @constraint(mymodel, vec(*(transpose(ones_vc), x_tensor[:,:,1])) - v .== 0)\n",
    "\n",
    "    # the squeeze of implicilty identical vectors, is shown below\n",
    "    for kdx = 2: k_depth\n",
    "        @constraint(mymodel, vec(*(x_tensor[:,:, (kdx - 1)], ones_vc)) - vec(*(transpose(ones_vc), x_tensor[:,:, kdx]) ) .== 0)\n",
    "    end  \n",
    "    # this is the trickiest constraint, and what is needed to convert this from quadratic to linear\n",
    "    # it exploits a 'hidden pmf' embodded in each implicit vector \n",
    "    # associated with a given level (kdx) of the x_tensor\n",
    "\n",
    "    # dummy constraint at the very end, maybe makes it a network problem? \n",
    "    @constraint(mymodel, - sum(x_tensor[:,:, k_depth])  == -1)\n",
    "    \n",
    "    my_z = LP_objective_function(L, A, y_vec, x_tensor, nominal_prior_x, v) # a scalar result\n",
    "\n",
    "    # if you know the score of the best case, the simplest way to get the second best score \n",
    "    # (i.e. second best > best) is: make variables binary integers\n",
    "    # then uncomment out the below two lines\n",
    "    # user_inputs_best_score = 3.92331 + 0.001\n",
    "    # second_best_constraint = @constraint(mymodel, my_z >= user_inputs_best_score) \n",
    "    # unlike the above constraints this is a linear inequality, however.  \n",
    "\n",
    "    myobjective = @objective(mymodel, Min, my_z ) # basic linear form\n",
    "    # Solve mymodel\n",
    "    solve(mymodel)\n",
    "\n",
    "    # println(\"Variable x:Values: \", getvalue(x))\n",
    "\n",
    "    println(\"Objective value: \", getobjectivevalue(mymodel))\n",
    "    return k_depth, v, x_tensor, ones_vc\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objective value: 3.9233170120469048\n"
     ]
    }
   ],
   "source": [
    "my_y_vec = [2, 3, 3, 3];\n",
    "\n",
    "# my_y_vec = rand(1:3, 100000);\n",
    "# if you want to try running the LP on a much larger case\n",
    "# uncomment out the above line, and run it \n",
    "\n",
    "k_depth, v, x_tensor, ones_vc = do_the_LP(my_y_vec);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The below prints out an interpretable form of the results \n",
      "[1.0,0.0]\n",
      "[1.0,0.0]\n",
      "[0.0,1.0]\n",
      "[0.0,1.0]\n",
      "[0.0,1.0]\n",
      "\n",
      "note due to floating point issues, a value like 0.999999, it should be interpretted as 1.0"
     ]
    }
   ],
   "source": [
    "print(\"The below prints out an interpretable form of the results \\n\")\n",
    "print(getvalue(v))\n",
    "for k = 1:k_depth\n",
    "    result = vec(*(x_tensor[:,:,k], ones_vc))\n",
    "    print(\"\\n\", getvalue(result))\n",
    "end\n",
    "\n",
    "print(\"\\n\\nnote due to floating point issues, a value like 0.999999, it should be interpretted as 1.0\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.4.5",
   "language": "julia",
   "name": "julia-0.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
